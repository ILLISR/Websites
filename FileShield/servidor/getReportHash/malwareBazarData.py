import pandas as pd
import requests
from io import StringIO
import csv
from datetime import datetime, timedelta

# Descargar los datos del feed
url = "https://bazaar.abuse.ch/export/csv/recent/"
response = requests.get(url)
data = response.text

# Mostrar las primeras 40 líneas sin procesar
lines = data.splitlines()
for line in lines[:40]:
    print(line)

# Eliminar comentarios y líneas en blanco
lines = [line for line in lines if not line.startswith('#') and line.strip()]

# Procesar los datos con csv.reader para manejar las inconsistencias
csv_data = csv.reader(lines)
clean_data = []
for row in csv_data:
    if len(row) == 14:  # Solo considerar filas con el número correcto de columnas
        clean_data.append(row)

# Convertir a DataFrame
columns = ["FirstSeenUtc", "SHA256", "MD5", "SHA1", "Reporter", "FileName", "FileType", "MimeType", "Signer", "ClamAV", "VTPercent", "ImpHash", "SSDeep", "TLSH"]
df = pd.DataFrame(clean_data, columns=columns)

# Limpiar las columnas eliminando espacios y comillas adicionales
df = df.apply(lambda x: x.str.strip().str.replace('"', '') if x.dtype == "object" else x)

# Imprimir las primeras filas del DataFrame antes de cualquier procesamiento
print("DataFrame inicial:")
print(df.head(40))

# Convertir la columna de fecha a datetime
df["FirstSeenUtc"] = pd.to_datetime(df["FirstSeenUtc"], format="%Y-%m-%d %H:%M:%S", errors='coerce')

# Eliminar duplicados basados en SHA256
df = df.drop_duplicates(subset=['SHA256'])

# Filtrar y limpiar datos
df["Signer"] = df["Signer"].replace('n/a', '')
df["ClamAV"] = df["ClamAV"].replace('n/a', '')
df["VTPercent"] = df["VTPercent"].replace('n/a', 0.0).astype(float)
df["ImpHash"] = df["ImpHash"].replace('n/a', '')
df["SSDeep"] = df["SSDeep"].replace('n/a', '')
df["TLSH"] = df["TLSH"].replace('n/a', '')

# Imprimir el DataFrame después de la limpieza
print("Abuse Feed DataFrame después de la limpieza:")
print(df)

# Supongamos que tienes otros dataframes con eventos de dispositivos
# Ajustando para usar algunos SHA256 del abuse_feed_df
if len(df) > 1:
    sample_sha256_1 = df.iloc[0]["SHA256"]
    sample_sha256_2 = df.iloc[1]["SHA256"]

    device_process_events_df = pd.DataFrame({
        "Timestamp": [datetime.utcnow(), datetime.utcnow() - timedelta(hours=1)],
        "SHA256": [sample_sha256_1, sample_sha256_2]
    })  # Cargar tus datos aquí
    device_file_events_df = pd.DataFrame({
        "Timestamp": [datetime.utcnow(), datetime.utcnow() - timedelta(hours=2)],
        "SHA256": [sample_sha256_1, sample_sha256_2]
    })  # Cargar tus datos aquí
    device_image_load_events_df = pd.DataFrame({
        "Timestamp": [datetime.utcnow(), datetime.utcnow() - timedelta(hours=3)],
        "SHA256": [sample_sha256_1, sample_sha256_2]
    })  # Cargar tus datos aquí

    # Filtrar eventos recientes
    max_age = datetime.utcnow() - timedelta(days=1000)
    device_process_events_df = device_process_events_df[device_process_events_df['Timestamp'] > max_age]
    device_file_events_df = device_file_events_df[device_file_events_df['Timestamp'] > max_age]
    device_image_load_events_df = device_image_load_events_df[device_image_load_events_df['Timestamp'] > max_age]

    # Imprimir los DataFrames de eventos de dispositivos
    print("Device Process Events DataFrame:")
    print(device_process_events_df)
    print("Device File Events DataFrame:")
    print(device_file_events_df)
    print("Device Image Load Events DataFrame:")
    print(device_image_load_events_df)

    # Realizar las uniones
    merged_df1 = pd.merge(df, device_process_events_df, on='SHA256', how='inner')
    merged_df2 = pd.merge(df, device_file_events_df, on='SHA256', how='inner')
    merged_df3 = pd.merge(df, device_image_load_events_df, on='SHA256', how='inner')

    # Imprimir los DataFrames después de las uniones
    print("Merged DataFrame 1 (Process Events):")
    print(merged_df1)
    print("Merged DataFrame 2 (File Events):")
    print(merged_df2)
    print("Merged DataFrame 3 (Image Load Events):")
    print(merged_df3)

    # Combinar todos los resultados
    final_result_df = pd.concat([merged_df1, merged_df2, merged_df3])

    # Exportar el resultado final a un archivo JSON
    final_result_df.to_json("final_result.json", orient="records", lines=True)

    # Mostrar el resultado final (opcional)
    print("Final Result DataFrame:")
    print(final_result_df)
else:
    print("Not enough data in abuse feed to perform merges.")
